version: '3.8'

services:
  rag-app:
    build:
      context: .
      dockerfile: Dockerfile
    ports:
      - "8000:8000"
    environment:
      # Application settings
      - APP_NAME=RAG System API
      - APP_VERSION=1.0.0
      - LOG_LEVEL=INFO

      # Database settings
      - CHROMA_DB_PATH=/app/chroma_db

      # API settings (optional - for production use)
      # - OPENROUTER_API_KEY=your_api_key_here

      # Model settings
      - EMBEDDING_MODEL=all-MiniLM-L6-v2
      - LLM_MODEL=openai/gpt-3.5-turbo

      # Performance settings
      - MAX_SEARCH_RESULTS=20
      - MAX_CHAT_RESULTS=10
      - MAX_DOCUMENT_LENGTH=10000
    volumes:
      # Persist database data
      - ./chroma_db:/app/chroma_db
      # Optional: Mount additional data directory
      - ./data:/app/data
    restart: unless-stopped
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8000/health"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 40s

  # Optional: Add a reverse proxy for production
  nginx:
    image: nginx:alpine
    ports:
      - "80:80"
      - "443:443"
    volumes:
      - ./docker/nginx.conf:/etc/nginx/nginx.conf:ro
      - ./docker/ssl:/etc/nginx/ssl:ro  # For SSL certificates
    depends_on:
      - rag-app
    restart: unless-stopped
    profiles:
      - production

networks:
  default:
    name: rag-network
